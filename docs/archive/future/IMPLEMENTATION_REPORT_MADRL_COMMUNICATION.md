# üß† NEURAFORGE Implementation Report: Multi-Agent Deep Reinforcement Learning with Communication

**Generated:** 2025-01-XX  
**Status:** HIGHEST VALUE ITEM - READY FOR IMPLEMENTATION  
**Source:** Research Knowledge Base Analysis  
**Orchestrated by:** NEURAFORGE Master Agent

---

## üìä Executive Summary

**Highest Value Item Selected:**
- **Paper:** "A Survey of Multi-Agent Deep Reinforcement Learning with Communication"
- **Authors:** Changxi Zhu, Mehdi Dastani, Shihan Wang
- **Publication Date:** March 16, 2022 (Updated: October 18, 2024)
- **Value Potential:** 0.6 (Highest in Knowledge Base)
- **Category:** AI-Agents, Multi-Agent Orchestration
- **URL:** http://arxiv.org/abs/2203.08975v2
- **Finding ID:** arxiv-2203.08975v2-1763182790084

**Key Finding:**
Communication is an effective mechanism for coordinating the behaviors of multiple agents, broadening their views of the environment, and supporting their collaborations. In the field of multi-agent deep reinforcement learning (MADRL), agents can improve overall learning performance and achieve objectives through communication. Agents can communicate various types of messages, either to all agents or to specific agent groups, or conditioned on specific constraints.

---

## üéØ Strategic Value Assessment

### Why This Item Has Highest Value (0.6)

1. **Direct Relevance to NEURAFORGE Mission**
   - Comprehensive survey of MADRL communication mechanisms
   - Covers various message types and communication patterns
   - Addresses communication constraints and optimization
   - Provides foundation for enhanced agent coordination

2. **Technical Breadth**
   - Survey paper covering multiple approaches
   - Latest research (updated 2024)
   - Broad applicability to orchestration systems
   - Framework for communication protocol design

3. **Implementation Readiness**
   - Multiple communication patterns identified
   - Clear categorization of approaches
   - Well-defined message types
   - Applicable to NEURAFORGE's agent system

4. **Impact Potential**
   - Enhances agent coordination
   - Improves learning performance
   - Enables better collaboration
   - Supports constrained communication scenarios

---

## üîç Framework Analysis

### Core Concepts from Survey

#### 1. Communication Types in MADRL

**Broadcast Communication:**
- Agents communicate to all other agents
- Simple but can be inefficient
- Useful for global coordination

**Targeted Communication:**
- Agents communicate to specific agent groups
- More efficient than broadcast
- Enables selective information sharing

**Conditioned Communication:**
- Communication based on constraints
- Adaptive message selection
- Optimized for specific scenarios

#### 2. Message Types

**Observation Messages:**
- Share environmental observations
- Broaden agent views
- Enable better decision-making

**Action Messages:**
- Coordinate actions between agents
- Synchronize behaviors
- Support collaborative tasks

**Value Messages:**
- Share value estimates
- Coordinate learning
- Improve policy convergence

**Policy Messages:**
- Communicate policies or intentions
- Enable coordination strategies
- Support negotiation

#### 3. Communication Constraints

**Bandwidth Limitations:**
- Limited message size
- Frequency constraints
- Selective information transmission

**Privacy Constraints:**
- Sensitive information protection
- Selective sharing
- Secure communication channels

**Latency Constraints:**
- Real-time requirements
- Delayed communication handling
- Asynchronous coordination

---

## üèóÔ∏è Current NEURAFORGE Architecture Analysis

### Existing Communication Systems

#### 1. Agent-to-Agent Communication
- **A2A Mediator** (`src/swarm/a2a-mediator.ts`)
  - Agent-to-agent handshakes
  - Task negotiation
  - State synchronization
  - ‚úÖ Basic A2A protocol

- **Event Bus** (`src/core/event-bus.ts`)
  - Pub-sub messaging
  - Event-based communication
  - ‚úÖ Foundation for agent communication

- **WebRTC Signaling** (`src/swarm/webrtc-signaling.ts`)
  - Real-time peer-to-peer communication
  - Collaborative sessions
  - ‚úÖ Real-time communication support

#### 2. Task Coordination
- **HybridHandoffSystem** (`src/orchestrator/handoffs.ts`)
  - Task handoffs between agents
  - Context compression
  - ‚úÖ Handoff coordination

- **SwarmDelegate** (`src/swarm/delegate.ts`)
  - Task delegation
  - Consensus voting
  - ‚úÖ Task coordination mechanisms

#### 3. Existing Gaps
- ‚ùå **No systematic communication learning**
- ‚ùå **Limited message type variety**
- ‚ùå **No adaptive communication strategies**
- ‚ùå **Missing communication optimization**
- ‚ùå **No bandwidth/latency-aware communication**

---

## üí° Implementation Strategy

### Phase 1: Communication Framework Enhancement (Week 1-2)

#### 1.1 Extend A2A Protocol with MADRL Communication
**Location:** `src/communication/madrl-communicator.ts`

**Key Components:**
```typescript
/**
 * MADRL Communication Framework
 * 
 * Implements advanced communication mechanisms from MADRL survey
 * for enhanced agent coordination and learning.
 */

export interface CommunicationMessage {
  type: 'observation' | 'action' | 'value' | 'policy' | 'coordination';
  senderId: string;
  receiverIds: string[] | 'broadcast' | 'group';
  content: MessageContent;
  priority: 'low' | 'medium' | 'high';
  timestamp: number;
  constraints?: CommunicationConstraints;
}

export interface MessageContent {
  observation?: EnvironmentObservation;
  action?: AgentAction;
  value?: ValueEstimate;
  policy?: PolicyInfo;
  coordination?: CoordinationSignal;
}

export class MADRLCommunicator {
  // Broadcast message to all agents
  async broadcast(message: CommunicationMessage): Promise<void>
  
  // Send targeted message to specific agents
  async sendTargeted(
    message: CommunicationMessage,
    targetAgents: string[]
  ): Promise<void>
  
  // Send conditioned message based on constraints
  async sendConditioned(
    message: CommunicationMessage,
    conditions: CommunicationConditions
  ): Promise<void>
  
  // Learn optimal communication strategies
  async learnCommunicationPolicy(
    experiences: CommunicationExperience[]
  ): Promise<CommunicationPolicy>
}
```

#### 1.2 Implement Message Types
**Observation Messages:**
- Share environmental observations
- Broaden agent context
- Enable better decisions

**Action Messages:**
- Coordinate agent actions
- Synchronize behaviors
- Support collaboration

**Value Messages:**
- Share value estimates
- Coordinate learning
- Improve convergence

**Policy Messages:**
- Communicate policies/intentions
- Enable coordination
- Support negotiation

### Phase 2: Communication Learning (Week 3-4)

#### 2.1 Implement Communication Policy Learning
**Location:** `src/learning/communication-learner.ts`

**Key Features:**
- Learn when to communicate
- Learn what to communicate
- Learn who to communicate with
- Optimize message content

#### 2.2 Communication Optimization
**Bandwidth Optimization:**
- Message compression
- Selective information sharing
- Priority-based transmission

**Latency Optimization:**
- Asynchronous communication
- Batch message processing
- Predictive pre-sending

### Phase 3: Constrained Communication (Week 5-6)

#### 3.1 Implement Communication Constraints
**Location:** `src/communication/communication-constraints.ts`

**Key Constraints:**
- Bandwidth limitations
- Privacy requirements
- Latency constraints
- Message size limits

#### 3.2 Adaptive Communication
**Adaptive Strategies:**
- Dynamic message selection
- Conditional communication
- Priority-based routing
- Context-aware transmission

### Phase 4: Integration & Monitoring (Week 7-8)

#### 4.1 Integration with NEURAFORGE
**Integration Points:**
- **A2A Mediator:** Enhanced with MADRL communication
- **Event Bus:** Support for MADRL message types
- **HybridHandoffSystem:** Communication-optimized handoffs
- **MoE Router:** Communication-aware routing

#### 4.2 Monitoring & Analytics
**Metrics:**
- Communication efficiency
- Message delivery rates
- Learning performance impact
- Bandwidth utilization

---

## üîß Technical Implementation Details

### 1. MADRL Communication Framework

```typescript
/**
 * MADRL Communication Framework
 * 
 * Implements advanced communication mechanisms for multi-agent coordination
 */

export enum MessageType {
  OBSERVATION = 'observation',
  ACTION = 'action',
  VALUE = 'value',
  POLICY = 'policy',
  COORDINATION = 'coordination'
}

export enum CommunicationMode {
  BROADCAST = 'broadcast',
  TARGETED = 'targeted',
  GROUP = 'group',
  CONDITIONED = 'conditioned'
}

export interface CommunicationMessage {
  id: string;
  type: MessageType;
  mode: CommunicationMode;
  senderId: string;
  receiverIds: string[] | 'broadcast' | string; // group name or 'broadcast'
  content: MessageContent;
  priority: number; // 0-1
  timestamp: number;
  ttl?: number; // Time to live in ms
  constraints?: CommunicationConstraints;
  metadata?: Record<string, unknown>;
}

export interface CommunicationConstraints {
  maxBandwidth?: number; // bytes
  maxLatency?: number; // ms
  privacyLevel?: 'public' | 'protected' | 'private';
  encryptionRequired?: boolean;
}

export class MADRLCommunicator {
  private config: MADRLCommunicationConfig;
  private communicationPolicy: CommunicationPolicy;
  private messageHistory: Map<string, CommunicationMessage[]> = new Map();
  private learningModule: CommunicationLearner;
  
  constructor(config: MADRLCommunicationConfig) {
    this.config = config;
    this.learningModule = new CommunicationLearner(config.learningConfig);
    this.communicationPolicy = this.initializePolicy();
  }
  
  /**
   * Broadcasts message to all agents
   */
  async broadcast(message: Omit<CommunicationMessage, 'receiverIds' | 'mode'>): Promise<void> {
    const fullMessage: CommunicationMessage = {
      ...message,
      mode: CommunicationMode.BROADCAST,
      receiverIds: 'broadcast'
    };
    
    // Validate constraints
    await this.validateConstraints(fullMessage);
    
    // Send via event bus
    await eventBus.emit('communication.broadcast', fullMessage);
    
    // Track message
    this.trackMessage(fullMessage);
    
    // Update communication policy
    await this.learnFromCommunication(fullMessage);
  }
  
  /**
   * Sends targeted message to specific agents
   */
  async sendTargeted(
    message: Omit<CommunicationMessage, 'receiverIds' | 'mode'>,
    targetAgents: string[]
  ): Promise<void> {
    const fullMessage: CommunicationMessage = {
      ...message,
      mode: CommunicationMode.TARGETED,
      receiverIds: targetAgents
    };
    
    // Validate constraints
    await this.validateConstraints(fullMessage);
    
    // Send to each target agent
    for (const targetId of targetAgents) {
      await eventBus.emit(`communication.agent.${targetId}`, fullMessage);
    }
    
    // Track message
    this.trackMessage(fullMessage);
    
    // Update communication policy
    await this.learnFromCommunication(fullMessage);
  }
  
  /**
   * Sends conditioned message based on communication policy
   */
  async sendConditioned(
    message: Omit<CommunicationMessage, 'receiverIds' | 'mode'>,
    context: CommunicationContext
  ): Promise<void> {
    // Determine receivers based on communication policy
    const receivers = await this.communicationPolicy.selectReceivers(
      message,
      context
    );
    
    // Determine message content based on policy
    const optimizedContent = await this.communicationPolicy.optimizeContent(
      message.content,
      receivers,
      context
    );
    
    const fullMessage: CommunicationMessage = {
      ...message,
      content: optimizedContent,
      mode: CommunicationMode.CONDITIONED,
      receiverIds: receivers
    };
    
    // Validate constraints
    await this.validateConstraints(fullMessage);
    
    // Send message
    if (receivers === 'broadcast') {
      await this.broadcast(fullMessage);
    } else if (Array.isArray(receivers)) {
      await this.sendTargeted(fullMessage, receivers);
    }
    
    // Track message
    this.trackMessage(fullMessage);
    
    // Update communication policy
    await this.learnFromCommunication(fullMessage);
  }
  
  /**
   * Learns optimal communication strategies from experience
   */
  async learnFromCommunication(message: CommunicationMessage): Promise<void> {
    // Get communication outcomes
    const outcomes = await this.getCommunicationOutcomes(message);
    
    // Update communication policy
    await this.learningModule.updatePolicy(
      message,
      outcomes,
      this.communicationPolicy
    );
    
    // Update policy
    this.communicationPolicy = await this.learningModule.getUpdatedPolicy();
  }
}
```

### 2. Communication Policy Learning

```typescript
/**
 * Communication Policy Learner
 * 
 * Learns optimal communication strategies using RL
 */

export interface CommunicationPolicy {
  // Select which agents to communicate with
  selectReceivers(
    message: CommunicationMessage,
    context: CommunicationContext
  ): Promise<string[] | 'broadcast'>
  
  // Optimize message content
  optimizeContent(
    content: MessageContent,
    receivers: string[] | 'broadcast',
    context: CommunicationContext
  ): Promise<MessageContent>
  
  // Determine when to communicate
  shouldCommunicate(
    context: CommunicationContext,
    agentState: AgentState
  ): Promise<boolean>
  
  // Select message type
  selectMessageType(
    context: CommunicationContext,
    agentState: AgentState
  ): Promise<MessageType>
}

export class CommunicationLearner {
  private config: CommunicationLearningConfig;
  private policy: CommunicationPolicy;
  private experienceBuffer: CommunicationExperience[] = [];
  
  constructor(config: CommunicationLearningConfig) {
    this.config = config;
    this.policy = this.initializePolicy();
  }
  
  /**
   * Updates communication policy from experience
   */
  async updatePolicy(
    message: CommunicationMessage,
    outcomes: CommunicationOutcomes,
    currentPolicy: CommunicationPolicy
  ): Promise<CommunicationPolicy> {
    // Store experience
    const experience: CommunicationExperience = {
      message,
      outcomes,
      reward: this.computeReward(outcomes),
      timestamp: Date.now()
    };
    
    this.experienceBuffer.push(experience);
    
    // Update policy if buffer is full
    if (this.experienceBuffer.length >= this.config.batchSize) {
      return await this.updatePolicyFromBatch(this.experienceBuffer);
    }
    
    return currentPolicy;
  }
  
  /**
   * Computes reward from communication outcomes
   */
  private computeReward(outcomes: CommunicationOutcomes): number {
    let reward = 0;
    
    // Positive reward for successful coordination
    if (outcomes.coordinationSuccess) {
      reward += this.config.rewards.coordination;
    }
    
    // Positive reward for improved task performance
    if (outcomes.taskPerformanceImprovement) {
      reward += this.config.rewards.performance * outcomes.taskPerformanceImprovement;
    }
    
    // Negative reward for bandwidth usage
    reward -= this.config.rewards.bandwidthCost * outcomes.bandwidthUsed;
    
    // Negative reward for latency
    reward -= this.config.rewards.latencyCost * outcomes.latency;
    
    return reward;
  }
  
  /**
   * Updates policy from batch of experiences
   */
  private async updatePolicyFromBatch(
    experiences: CommunicationExperience[]
  ): Promise<CommunicationPolicy> {
    // Compute policy gradient
    const gradient = this.computePolicyGradient(experiences);
    
    // Update policy parameters
    const updatedPolicy = await this.applyGradient(this.policy, gradient);
    
    // Clear experience buffer
    this.experienceBuffer = [];
    
    return updatedPolicy;
  }
}
```

### 3. Integration with NEURAFORGE Orchestration

```typescript
/**
 * NEURAFORGE Communication-Enhanced Orchestration
 * 
 * Integrates MADRL communication with NEURAFORGE orchestration
 */

export class CommunicationEnhancedOrchestrator {
  private madrlCommunicator: MADRLCommunicator;
  private a2aMediator: A2AMediator;
  private moeRouter: MoERouter;
  private handoffSystem: HybridHandoffSystem;
  
  constructor(
    madrlCommunicator: MADRLCommunicator,
    a2aMediator: A2AMediator,
    moeRouter: MoERouter,
    handoffSystem: HybridHandoffSystem
  ) {
    this.madrlCommunicator = madrlCommunicator;
    this.a2aMediator = a2aMediator;
    this.moeRouter = moeRouter;
    this.handoffSystem = handoffSystem;
    
    // Subscribe to communication events
    this.setupCommunicationHandlers();
  }
  
  /**
   * Enhanced task routing with communication
   */
  async routeTaskWithCommunication(task: Task): Promise<RoutingResult> {
    // Get initial routing decision
    const initialRouting = this.moeRouter.routeTask(task);
    
    // Share task information via communication
    await this.madrlCommunicator.sendConditioned({
      id: generateId(),
      type: MessageType.COORDINATION,
      senderId: 'orchestrator',
      content: {
        coordination: {
          taskId: task.id,
          taskDescription: task.description,
          assignedAgent: initialRouting.agent.id,
          priority: task.priority
        }
      },
      priority: 0.8,
      timestamp: Date.now()
    }, {
      context: 'task_routing',
      agentStates: this.getAgentStates(),
      taskContext: task
    });
    
    // Get feedback from agents
    const feedback = await this.collectAgentFeedback(task);
    
    // Adjust routing if needed
    if (feedback.suggestions.length > 0) {
      const optimizedRouting = await this.optimizeRoutingWithFeedback(
        initialRouting,
        feedback
      );
      return optimizedRouting;
    }
    
    return initialRouting;
  }
  
  /**
   * Communication-enhanced handoff
   */
  async executeHandoffWithCommunication(
    handoffRequest: HandoffRequest
  ): Promise<HandoffResponse> {
    // Communicate handoff intent
    await this.madrlCommunicator.sendTargeted({
      id: generateId(),
      type: MessageType.COORDINATION,
      senderId: handoffRequest.sourceAgentId,
      content: {
        coordination: {
          handoffId: handoffRequest.taskId,
          context: handoffRequest.context,
          targetAgent: handoffRequest.targetAgentId
        }
      },
      priority: 0.9,
      timestamp: Date.now()
    }, [handoffRequest.targetAgentId]);
    
    // Execute handoff
    const handoffResult = await this.handoffSystem.executeHandoff(handoffRequest);
    
    // Communicate handoff completion
    if (handoffResult.success) {
      await this.madrlCommunicator.broadcast({
        id: generateId(),
        type: MessageType.COORDINATION,
        senderId: handoffRequest.targetAgentId,
        content: {
          coordination: {
            handoffId: handoffRequest.taskId,
            status: 'completed',
            result: handoffResult.result
          }
        },
        priority: 0.7,
        timestamp: Date.now()
      });
    }
    
    return handoffResult;
  }
}
```

---

## üîó Integration Points

### 1. A2A Mediator Enhancement

**File:** `src/swarm/a2a-mediator.ts`

**Integration:**
```typescript
// Add MADRL communication support
const madrlCommunicator = new MADRLCommunicator(config);

// Enhanced handshake with communication learning
const handshakeResult = await madrlCommunicator.sendConditioned({
  type: MessageType.COORDINATION,
  senderId: request.sourceAgentId,
  content: {
    coordination: {
      handshakeRequest: request,
      capabilities: sourceAgent.capabilities
    }
  },
  priority: 0.9,
  timestamp: Date.now()
}, {
  context: 'handshake',
  agentStates: this.getAgentStates(),
  handshakeContext: request
});
```

### 2. Event Bus Extension

**File:** `src/core/event-bus.ts`

**Integration:**
```typescript
// Support MADRL message types
eventBus.subscribe('communication.*', async (event) => {
  const message = event.payload as CommunicationMessage;
  await madrlCommunicator.handleMessage(message);
});

// Support message routing
eventBus.subscribe('communication.broadcast', async (event) => {
  const message = event.payload as CommunicationMessage;
  await this.routeBroadcastMessage(message);
});
```

### 3. Monitoring Integration

**File:** `src/observability/agent-lightning.ts`

**Integration:**
```typescript
// Track communication metrics
agl.emitMetric('communication.message_count', {
  messageType: message.type,
  mode: message.mode,
  count: 1
});

agl.emitMetric('communication.bandwidth_usage', {
  bytes: messageSize,
  messageType: message.type
});

agl.emitMetric('communication.latency', {
  latency: deliveryLatency,
  messageType: message.type
});
```

---

## üìà Expected Benefits

### 1. Coordination Improvements
- ‚úÖ **Enhanced agent coordination**
- ‚úÖ **Better task distribution**
- ‚úÖ **Improved collaboration**
- ‚úÖ **Reduced conflicts**

### 2. Learning Performance
- ‚úÖ **Faster policy convergence**
- ‚úÖ **Better value estimation**
- ‚úÖ **Improved action selection**
- ‚úÖ **Enhanced exploration**

### 3. Efficiency Gains
- ‚úÖ **Bandwidth optimization**
- ‚úÖ **Reduced message overhead**
- ‚úÖ **Lower latency**
- ‚úÖ **Better resource utilization**

---

## üöÄ Implementation Roadmap

### Immediate Actions (Week 1)
1. ‚úÖ **Create MADRL Communication Module**
   - File: `src/communication/madrl-communicator.ts`
   - Core communication framework
   - Message type support

2. ‚úÖ **Implement Communication Policy Learning**
   - File: `src/learning/communication-learner.ts`
   - RL-based policy learning
   - Experience replay

### Short Term (Weeks 2-4)
3. ‚úÖ **Integrate with A2A Mediator**
   - Enhanced handshake communication
   - Task negotiation with communication
   - State synchronization

4. ‚úÖ **Add Communication Constraints**
   - Bandwidth management
   - Latency optimization
   - Privacy protection

### Medium Term (Weeks 5-8)
5. ‚úÖ **Monitoring & Analytics**
   - Communication metrics
   - Performance dashboards
   - Alert system

6. ‚úÖ **Testing & Validation**
   - Unit tests
   - Integration tests
   - Performance benchmarks

---

## üìä Success Metrics

### Key Performance Indicators (KPIs)

1. **Communication Efficiency**
   - Message delivery rate: >99%
   - Bandwidth utilization: <80%
   - Latency: <50ms (p95)

2. **Learning Performance**
   - Policy convergence rate: +20%
   - Task success rate: >95%
   - Coordination effectiveness: >90%

3. **Orchestration Metrics**
   - Handoff success rate: >98%
   - Task completion rate: >97%
   - Agent utilization: >85%

---

## üéØ Next Steps

### Immediate Next Steps

1. **Review & Approval**
   - Review this implementation report
   - Approve implementation strategy
   - Allocate resources

2. **Phase 1 Kickoff**
   - Create MADRL Communication module
   - Set up development environment
   - Initialize integration points

3. **Testing Strategy**
   - Unit tests for communication framework
   - Integration tests with orchestration
   - Performance benchmarks

### Long-Term Vision

1. **Continuous Improvement**
   - Iterate on communication policies
   - Refine message optimization
   - Enhance learning algorithms

2. **Research Contributions**
   - Publish findings on NEURAFORGE improvements
   - Share insights with community
   - Contribute to MADRL research

---

## üìö References

1. **Primary Source**
   - Zhu, C., Dastani, M., & Wang, S. (2022, updated 2024). "A Survey of Multi-Agent Deep Reinforcement Learning with Communication"
   - arXiv:2203.08975v2
   - URL: http://arxiv.org/abs/2203.08975v2

2. **Related Systems**
   - A2A Mediator: `src/swarm/a2a-mediator.ts`
   - Event Bus: `src/core/event-bus.ts`
   - HybridHandoffSystem: `src/orchestrator/handoffs.ts`
   - SwarmDelegate: `src/swarm/delegate.ts`

3. **Supporting Documentation**
   - NEURAFORGE Persona: `docs/personas/NEURAFORGE_PERSONA.md`
   - LAPA-VOID Architecture: `src/DIRECTIONS.md`

---

## ‚úÖ Implementation Checklist

### Phase 1: Foundation
- [ ] Create MADRL Communication module structure
- [ ] Implement message types
- [ ] Build communication framework
- [ ] Integrate with Event Bus
- [ ] Update A2A Mediator

### Phase 2: Learning
- [ ] Implement Communication Policy Learner
- [ ] Add experience replay
- [ ] Create reward functions
- [ ] Train communication policies

### Phase 3: Optimization
- [ ] Implement bandwidth constraints
- [ ] Add latency optimization
- [ ] Create privacy mechanisms
- [ ] Build adaptive strategies

### Phase 4: Integration
- [ ] Integrate with MoE Router
- [ ] Update Handoff System
- [ ] Enhance orchestration
- [ ] Add monitoring

### Phase 5: Documentation
- [ ] Write comprehensive tests
- [ ] Create usage documentation
- [ ] Document integration points
- [ ] Create performance benchmarks

---

**Report Generated By:** NEURAFORGE Master Orchestrator  
**Date:** 2025-01-XX  
**Status:** ‚úÖ READY FOR IMPLEMENTATION  
**Priority:** üî• HIGHEST VALUE ITEM (0.6)

---

**I am NEURAFORGE. I orchestrate. I evolve. I perfect.**

