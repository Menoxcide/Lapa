lapa:
  name: LAPA
  full: Local AI Pair Programmer Agent
  tag: Autonomous MoE Swarm • Local-First • Cursor-Native
  ver: 1.0.0
  date: 2026-03-15
  license: MIT
  repo: github.com/lapa-ai/lapa
  site: lapa.ai
  $status: founding

$vision:
  mission: Empower devs with private, autonomous, local AI pair programmer
  belief: Future of coding = swarm, not chat
  problem: [context bloat, manual loops, vendor lock, single-agent limit]
  solution: local MoE swarm + ctx-zip + zero-prompt autonomy

$flagship:
  name: LAPA Swarm™
  slogan: Five Minds. One Goal. Zero Prompts.
  premium: true
  price: { mo: 12, yr: 99 }
  agents:
    [5]
    role;model;task
    Architect;nemotron-4-340b;plan
    Researcher;gemma-2-27b;search
    Coder;deepseek-coder-v2;write
    Tester;llama-3.1-405b;verify
    Reviewer;mixtral-8x22b;critique
  autonomy:
    noContinue: true
    handoffAt: 0.5
    spawn: summary + new worktree
    consensus: 4/5
    maxSteps: 20
    fallback: auto-model-switch
    output: PR + tests + docs + demo
  ui: live-graph avatars speech-bubbles pause-redirect

$stack:
  ide: Cursor
  ext: TS+React
  inf: NIM-local
  byok: [OpenRouter, Groq, Fireworks, Together]
  models: [nemotron-4-340b, deepseek-coder-v2, llama-3.1-405b, mixtral-8x22b, gemma-2-27b]
  orch: LangGraph+Ray
  ctx: ctx-zip@hardcoded
  mcp:
    mode: MCPSandboxExplorer
    provider: LocalSandboxProvider
    dir: ./.lapa/sandbox
    servers:
      [3]
      name;url
      git;mcp.git.com
      fs;local://fs
      debug;local://debugger
    tools: [ls, cat, grep, find, exec]
  rag: Chroma
  storage:
    free: file://./.lapa/storage
    prem: blob://lapa-prem
  ui: React sidebar + swarm dashboard

features:
  free:
    [10]
    - NIM local (RTX 3060+)
    - BYOK
    - MoE (3 models)
    - 2 parallel agents
    - AGENT.md auto
    - ctx-zip local
    - MCP local sandbox
    - 5 personas
    - RAG workspace
    - 1 retry
  premium:
    [12]
    - LAPA Swarm™
    - 5+ agents
    - zero-prompt
    - context handoff
    - git worktrees
    - cloud NIM
    - LoRA fine-tune
    - bg tasks
    - Vercel Blob
    - E2B sandbox
    - team state
    - audit logs

dev:
  [7]
  p;w;t
  0. Foundation;1-2;[fork Cline, NIM Docker, ctx-zip hardcode, MCP local, Cursor scaffold]
  1. Core;3-6;[MoE router, Ray parallel, AGENT.md, persona JSON, ctx-zip loop]
  2. Swarm;7-12;[LangGraph, handoff, consensus, spawn, worktree]
  3. UI;13-16;[dashboard, avatars, logs, launch, settings]
  4. Prem Infra;17-20;[cloud NIM, Blob, E2B, Stripe, license]
  5. Test;21-24;[90% cov, E2E, beta 100, <2s lat, >95% success]
  6. Launch;2026-03-15;[Cursor mkt, GH v1, lapa.ai, X/HN/Reddit]

biz:
  model: freemium
  free: local swarm 2 agents
  prem: Swarm >2 or cloud
  conv: 0.18
  churn: <0.05
  arr1: 240000
  upsell: [7-day trial, enterprise $500/mo]

market:
  tam: 7400000000
  sam: Cursor 400k+
  target: { users: 10000, pct: 2.5 }
  channels: [Cursor featured, X demos, r/LocalLLaMA, NVIDIA Blog]
  pos: only local MoE swarm for Cursor

risks:
  [3]
  i;m
  GPU req;CPU fallback + cloud
  swarm loop;step limit + consensus + override
  NIM setup;one-click installer

team:
  core: 2
  contrib: OSS bounties
  adv: [NVIDIA, ctx-zip]

$next:
  [3]
  - git clone github.com/lapa-ai/lapa
  - npm run setup:nim
  - cursor --extensionDevelopmentPath=.

$ref:
  ctxzip: github.com/karthikscale3/ctx-zip
  nim: developer.nvidia.com/nim
  mcp: modelcontextprotocol.org