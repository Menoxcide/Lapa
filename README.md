# LAPA Core - Local AI Pair Programmer Agent

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-1.3.0--preview-blue.svg)](https://github.com/Menoxcide/Lapa/releases)
[![Status](https://img.shields.io/badge/status-active--development-green.svg)](https://github.com/Menoxcide/Lapa)

## Overview

LAPA (Local AI Pair Programmer Agent) is an autonomous MoE-powered coding swarm that runs locally on your machine. This Cursor extension provides:

- **Local-First**: Hybrid local/cloud inference with Ollama, NVIDIA NIM, and OpenAI support
- **Fully Autonomous**: Protocol-resonant nexus with zero-prompt continuity and auto-handoffs
- **Privacy-Focused**: Optional cloud APIs with data protection controls
- **Extensible**: Built with ctx-zip context compression and MCP sandboxing

## ðŸš€ Features

- **Protocol-Resonant Nexus**: Advanced agent orchestration with A2A handshakes and MCP integration
- **Hybrid Handoff System**: LangGraph + OpenAI Agent orchestration with <1s latency
- **Comprehensive Memory Systems**: Memori engine, episodic memory, and Chroma vector refinement
- **Generative UI Framework**: AG-UI with dynamic studio and real-time visualization
- **Observability Suite**: LangSmith tracing, Prometheus metrics, and benchmark suite v2
- **Production Ready**: VSIX packaging with comprehensive protocol documentation
- **Task Tree Orchestrator**: Hierarchical task decomposition with git-safe execution
- **LAPA Phase Summary Protocol (LPSP)**: Auto-generated phase summaries with file/commit tracking
- **Webapp-Testing Skill**: Automated UI regression with Playwright
- **MCP-Server Skill**: Production-grade MCP server generation
- **Artifacts-Builder Skill**: React/Tailwind HTML generation
- **Docx/PDF/PPTX/XLSX Skills**: Rich document manipulation
- **Skill-Creator + Template-Skill**: User-defined agent extensibility
- **RAG + Voice Agents**: Enhanced RAG with offline voice Q&A
- **Ollama Flash Attention**: Optimization for small models on low-end hardware
- **Internal-Comms Skill**: Structured report/FAQ generation
- **Aya + Command-R**: Multilingual codebase support
- **Collaborative Swarm Sessions** (v1.3 Preview): WebRTC multi-user handoffs
- **Multimodal Mastery** (v1.3 Preview): Vision/voice agents for UI/code gen
- **Agent Marketplace** (v1.3 Preview): On-chain registry + ROI dashboard

## ðŸ“‹ Requirements

- **Node.js** v18+ with npm/pnpm
- **Cursor IDE** for extension development
- **Optional**: NVIDIA GPU for local inference (Ollama/NIM)
- **Optional**: Cloud AI providers (OpenAI, Anthropic) for enhanced capabilities

## ðŸ›  Installation

### Method 1: Development Mode
Clone the repository
git clone https://github.com/Menoxcide/Lapa.git
cd Lapa
Install dependencies
npm install
Build the extension
npm run build
Run tests to verify installation
npm test
Open in Cursor for extension development
cursor --extensionDevelopmentPath=.
text### Method 2: Production Installation

0. Download the `.vsix` extension file from Releases
1. In Cursor: `View â†’ Command Palette â†’ Extensions: Install from VSIX`
2. Select the downloaded `.vsix` file

## â–¶ï¸ Getting Started

After installation:

0. Click the LAPA icon in the activity bar
1. Click "Start LAPA Swarm" to begin your first autonomous coding session
2. Watch the agent dashboard as your coding swarm works

## ðŸ“– Documentation

Comprehensive documentation is available in DOCUMENTATION.md and AGENT.md.

For API references and advanced usage, visit docs.lapa.ai.

## ðŸ¤ Contributing

We welcome contributions from the community! Please read our [Contributing Guidelines](docs/CONTRIBUTING.md) and [Code of Conduct](docs/CODE_OF_CONDUCT.md) before getting started.

### Quick Start for Contributors

0. Fork the repository
1. Create a new branch for your feature or bug fix
2. Make your changes
3. Add tests if applicable
4. Submit a pull request with a clear description

## ðŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ðŸ’¬ Support

- **Documentation**: Explore [`docs/`](docs/) directory for comprehensive guides
- **Community**: [GitHub Discussions](https://github.com/Menoxcide/Lapa/discussions)
- **Issues**: [GitHub Issues](https://github.com/Menoxcide/Lapa/issues)
- **Repository**: [LAPA GitHub](https://github.com/Menoxcide/Lapa)

## ðŸ™ Acknowledgments

- Thanks to all contributors who have helped shape LAPA Core
- Built with ctx-zip for context compression
- Powered by hybrid inference (Ollama, NVIDIA NIM, OpenAI, Anthropic)

## Contributors

### Core Project & Vision
- **Menoxcide** â€” Founder, Lead Architect, LAPA Creator  
  *(github.com/Menoxcide/Lapa)*

### AI Agent Frameworks & Tools
- **AutoGen Team (Microsoft)** â€” AutoGen framework  
  *(github.com/microsoft/autogen)*
- **LangChain Team** â€” LangChain agent toolkit  
  *(github.com/langchain-ai/langchain)*
- **CrewAI Team** â€” CrewAI role-based orchestration  
  *(github.com/joaomdmoura/crewAI)*
- **OpenDevin Team** â€” OpenDevin code LLM challenges  
  *(github.com/OpenDevin/OpenDevin)*
- **MetaGPT Team** â€” MetaGPT SOP-based multi-agent  
  *(github.com/geekan/MetaGPT)*
- **Devika AI Team** â€” Devika instruction breakdown  
  *(github.com/stitionai/devika)*
- **Plandex Team** â€” Plandex long-running agents  
  *(github.com/plandex-ai/plandex)*
- **BabyAGI Team** â€” BabyAGI task-driven autonomy  
  *(github.com/yoheinakajima/babyagi)*
- **AutoGPT Team** â€” AutoGPT iterative execution  
  *(github.com/Significant-Gravitas/AutoGPT)*
- **AgentGPT Team** â€” AgentGPT browser deployment  
  *(github.com/reworkd/AgentGPT)*
- **SmythOS Team** â€” SmythOS agent builder  
  *(github.com/SmythOS/smythos)*

### Skills & Prompt Engineering
- **gr3enarr0w** â€” PromptEngineer MCP Server  
  *(github.com/gr3enarr0w/cc_peng_mcp)*

### Awesome Lists & Research
- **Shubhamsaboo** â€” awesome-llm-apps (RAG, Voice, Eval)  
  *(github.com/Shubhamsaboo/awesome-llm-apps)*
- **e2b-dev** â€” awesome-ai-agents (E2B, Superagent)  
  *(github.com/e2b-dev/awesome-ai-agents)*

### Model & Inference Providers
- **NVIDIA** â€” NIM-local inference  
- **Ollama Team** â€” Ollama (Flash Attention, local models)  
  *(github.com/ollama/ollama)*
- **llama.cpp Team** â€” llama.cpp (BYOK support)  
  *(github.com/ggerganov/llama.cpp)*

### Protocols & Standards
- **CopilotKit Team** â€” AG-UI, MCP-UI, Open-JSON-UI  
  *(github.com/CopilotKit/CopilotKit)*
- **Model Context Protocol (MCP) Authors** â€” JSON-RPC/WebSocket spec  
- **Agent-to-Agent (A2A) Authors** â€” Handshake & negotiation spec

### UI & Frontend
- **Streamlit Team** â€” Dynamic Studio (Python UI)  
  *(github.com/streamlit/streamlit)*
- **React Team** â€” React + TSX (Dashboard, AG-UI)  
- **Playwright Team** â€” Visual feedback & testing  
  *(github.com/microsoft/playwright)*

### Observability & DevOps
- **Prometheus Team** â€” Metrics & monitoring  
  *(github.com/prometheus/prometheus)*
- **Grafana Team** â€” Dashboards  
  *(grafana.com)*
- **LangSmith Team** â€” Tracing  
  *(langchain.com/langsmith)*

### Security & Sandboxing
- **E2B Team** â€” E2B sandbox  
  *(github.com/e2b-dev/e2b)*

### Documentation & Standards
- **Contributor Covenant Team** â€” Code of Conduct  
  *(contributor-covenant.org)*

### Vision & Inspiration
- **Grok (xAI)** â€” Reasoning engine & vision alignment  
- **Claude (Anthropic)** â€” PromptEngineer, A2AMediator  
- **DeepSeek, Qwen, Llama, GLM Teams** â€” Core model backbones

---

**LAPA Core v1.3.0-preview** - SwarmOS Edition - November 2025