{
  "finding": {
    "findingId": "reddit-1g62otv-1763179182909",
    "source": "reddit",
    "category": "model-quantization",
    "title": "ğ‹ğ€ğğ€: the first unsupervised pretraining method for Vision-Language-Action models. Outperforms SOTA models trained with ground-truth actions 30x more efficient than conventional VLA pretraining",
    "description": "**Project page:** [LAPA (latentactionpretraining.github.io)](https://latentactionpretraining.github.io/)\n\n\n\n# Abstract\n\nWe introduceÂ **L**atentÂ **A**ctionÂ **P**retraining for generalÂ **A**ction models (LAPA), the first unsupervised method for pretraining Vision-Language-Action (VLA) models without ground-truth robot action labels. Existing Vision-Language-Action models require action labels typically collected by human teleoperators during pretraining, which significantly limits possible data so",
    "data": {
      "query": "model quantization methods",
      "category": "model-quantization",
      "subreddit": "singularity",
      "score": 42,
      "numComments": 1,
      "author": "Gothsim10",
      "createdUtc": 1729202568,
      "sources": [
        "reddit"
      ]
    },
    "valuePotential": 0.05,
    "implementationSuggestion": "Explore model quantization methods for efficiency gains",
    "url": "https://reddit.com/r/singularity/comments/1g62otv/ğ‹ğ€ğğ€_the_first_unsupervised_pretraining_method/",
    "tags": [
      "model-quantization",
      "quantization",
      "model"
    ],
    "timestamp": "2025-11-15T03:59:42.909Z"
  },
  "storedAt": "2025-11-15T03:59:46.893Z",
  "accessedCount": 0,
  "lastAccessed": "2025-11-15T03:59:46.893Z",
  "implementationStatus": "pending"
}